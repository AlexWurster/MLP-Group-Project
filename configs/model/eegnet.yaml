defaults:
  - base_model_config

model_name: eegnet
configs:
  model_name_or_path: eegnet 
  from_pretrained: False
  pretrained_checkpoint: null # './saved/checkpoints/eegnet_epoch_52_best.pt'
model_args:
  n_chans: 16
  n_outputs: 6
  n_times: 10000
  F1: 8

# self.configs.model.num_attn_heads

# def __init__(
#             self,
#             n_chans=None, 
#             n_outputs=None,
#             n_times=None,
#             final_conv_length="auto",
#             pool_mode="mean",
#             F1=8,
#             D=2,
#             F2=16,  # usually set to F1*D (?)
#             kernel_length=64,
#             third_kernel_size=(8, 4),
#             drop_prob=0.25,
#             chs_info=None,
#             input_window_seconds=None,
#             sfreq=None,
#             in_chans=None,
#             n_classes=None,
#             input_window_samples=None,
#     ):
#         n_chans, n_outputs, n_times = deprecated_args(
#             self,
#             ("in_chans", "n_chans", in_chans, n_chans),
#             ("n_classes", "n_outputs", n_classes, n_outputs),
#             ("input_window_samples", "n_times", input_window_samples, n_times),
#         )
#         super().__init__(
#             n_outputs=n_outputs,
#             n_chans=n_chans,
#             chs_info=chs_info,
#             n_times=n_times,
#             input_window_seconds=input_window_seconds,
#             sfreq=sfreq,
#         )
#         del n_outputs, n_chans, chs_info, n_times, input_window_seconds, sfreq
#         del in_chans, n_classes, input_window_samples
#         if final_conv_length == "auto":
#             assert self.n_times is not None
#         self.final_conv_length = final_conv_length
#         self.pool_mode = pool_mode
#         self.F1 = F1
#         self.D = D
#         self.F2 = F2
#         self.kernel_length = kernel_length
#         self.third_kernel_size = third_kernel_size
#         self.drop_prob = drop_prob
#         # For the load_state_dict
#         # When padronize all layers,
#         # add the old's parameters here
#         self.mapping = {
#             "conv_classifier.weight": "final_layer.conv_classifier.weight",
#             "conv_classifier.bias": "final_layer.conv_classifier.bias"
#         }
